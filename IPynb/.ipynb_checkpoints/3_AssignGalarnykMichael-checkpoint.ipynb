{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<h1 align=\"center\"> Machine Learning: Assignment 3</h1><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor, ExtraTreesClassifier\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn import svm, neighbors\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Problem 1 Kaggle Titanic</h2><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><p style=\"font-size:120%;\"></strong> Train decision tree, forests of randomized trees and Boosting trained on the Titanic Data Set. Perform and plot the decision surface for each. Don’t forget to perform data prep. (Hint: Kaggle has a nice description­ https://www.kaggle.com/c/titanic).\n",
    "Perform feature importance analysis and plot histogram before the training. Several different configuration of each of the models/parameters should be explored, analyzed and plotted. Demonstrate how changes in parameters influences accuracy for different algorithms. Describe your process of parameter tuning and provide in detailed discussion of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 columns: ['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked']\n",
      "Row count: 1309\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "# read in the training and testing data into Pandas.DataFrame objects\n",
    "input_df = pd.read_csv('data/titanic/train.csv', header=0)\n",
    "submit_df  = pd.read_csv('data/titanic/test.csv',  header=0)\n",
    " \n",
    "# merge the two DataFrames into one\n",
    "df = pd.concat([input_df, submit_df])\n",
    " \n",
    "# re-number the combined data set so there aren't duplicate indexes\n",
    "df.reset_index(inplace=True)\n",
    " \n",
    "# reset_index() generates a new column that we don't want, so let's get rid of it\n",
    "df.drop('index', axis=1, inplace=True)\n",
    " \n",
    "# the remaining columns need to be reindexed so we can access the first column at '0' instead of '1'\n",
    "df = df.reindex_axis(input_df.columns, axis=1)\n",
    " \n",
    "print df.shape[1], \"columns:\", df.columns.values\n",
    "print \"Row count:\", df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex_female  Sex_male\n",
       "0            0.0       1.0\n",
       "1            1.0       0.0\n",
       "2            1.0       0.0\n",
       "3            1.0       0.0\n",
       "4            0.0       1.0\n",
       "5            0.0       1.0\n",
       "6            0.0       1.0\n",
       "7            0.0       1.0\n",
       "8            1.0       0.0\n",
       "9            1.0       0.0\n",
       "10           1.0       0.0\n",
       "11           1.0       0.0\n",
       "12           0.0       1.0\n",
       "13           0.0       1.0\n",
       "14           1.0       0.0\n",
       "15           1.0       0.0\n",
       "16           0.0       1.0\n",
       "17           0.0       1.0\n",
       "18           1.0       0.0\n",
       "19           1.0       0.0\n",
       "20           0.0       1.0\n",
       "21           0.0       1.0\n",
       "22           1.0       0.0\n",
       "23           0.0       1.0\n",
       "24           1.0       0.0\n",
       "25           1.0       0.0\n",
       "26           0.0       1.0\n",
       "27           0.0       1.0\n",
       "28           1.0       0.0\n",
       "29           0.0       1.0\n",
       "...          ...       ...\n",
       "1279         0.0       1.0\n",
       "1280         0.0       1.0\n",
       "1281         0.0       1.0\n",
       "1282         1.0       0.0\n",
       "1283         0.0       1.0\n",
       "1284         0.0       1.0\n",
       "1285         0.0       1.0\n",
       "1286         1.0       0.0\n",
       "1287         0.0       1.0\n",
       "1288         1.0       0.0\n",
       "1289         0.0       1.0\n",
       "1290         0.0       1.0\n",
       "1291         1.0       0.0\n",
       "1292         0.0       1.0\n",
       "1293         1.0       0.0\n",
       "1294         0.0       1.0\n",
       "1295         0.0       1.0\n",
       "1296         0.0       1.0\n",
       "1297         0.0       1.0\n",
       "1298         0.0       1.0\n",
       "1299         1.0       0.0\n",
       "1300         1.0       0.0\n",
       "1301         1.0       0.0\n",
       "1302         1.0       0.0\n",
       "1303         1.0       0.0\n",
       "1304         0.0       1.0\n",
       "1305         1.0       0.0\n",
       "1306         0.0       1.0\n",
       "1307         0.0       1.0\n",
       "1308         0.0       1.0\n",
       "\n",
       "[1309 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df['Sex'],prefix='Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Populate missing ages  using RandomForestClassifier\n",
    "def setMissingAges(df):\n",
    "    \n",
    "    # Grab all the features that can be included in a Random Forest Regressor\n",
    "    age_df = df[['Age','Embarked','Fare', 'Parch', 'SibSp', 'Pclass']]\n",
    "    \n",
    "    # Split into sets with known and unknown Age values\n",
    "    knownAge = age_df.loc[ (df.Age.notnull()) ]\n",
    "    unknownAge = age_df.loc[ (df.Age.isnull()) ]\n",
    "    \n",
    "    # All age values are stored in a target array\n",
    "    y = knownAge.values[:, 0]\n",
    "    \n",
    "    # All the other values are stored in the feature array\n",
    "    X = knownAge.values[:, 1::]\n",
    "    \n",
    "    # Create and fit a model\n",
    "    rtr = RandomForestRegressor(n_estimators=2000, n_jobs=-1)\n",
    "    rtr.fit(X, y)\n",
    "    \n",
    "    # Use the fitted model to predict the missing values\n",
    "    predictedAges = rtr.predict(unknownAge.values[:, 1::])\n",
    "    \n",
    "    # Assign those predictions to the full data set\n",
    "    df.loc[ (df.Age.isnull()), 'Age' ] = predictedAges \n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: S",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-adfd7f264731>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msetMissingAges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-a920c81ee214>\u001b[0m in \u001b[0;36msetMissingAges\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Create and fit a model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mrtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mrtr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Use the fitted model to predict the missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mgalarny/anaconda/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \"\"\"\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;31m# Pre-sort indices to avoid that each individual tree of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mgalarny/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    371\u001b[0m                                       force_all_finite)\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: S"
     ]
    }
   ],
   "source": [
    "setMissingAges(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    ('Fare',) -> 0.693602693603 (RF: 0.693602693603, ET: 0.68911335578, SVM: 0.652076318743, KNN: 0.667789001122)\n",
      "                                     ('Sex',) -> 0.786756453423 (RF: 0.786756453423, ET: 0.786756453423, SVM: 0.616161616162, KNN: 0.786756453423)\n",
      "                                  ('Pclass',) -> 0.679012345679 (RF: 0.679012345679, ET: 0.679012345679, SVM: 0.616161616162, KNN: 0.565656565657)\n",
      "                                ('Embarked',) -> 0.636363636364 (RF: 0.636363636364, ET: 0.636363636364, SVM: 0.616161616162, KNN: 0.628507295174)\n",
      "                                     ('Age',) -> 0.628507295174 (RF: 0.578002244669, ET: 0.590347923681, SVM: 0.628507295174, KNN: 0.571268237935)\n",
      "                              ('Fare', 'Sex') -> 0.786756453423 (RF: 0.776655443322, ET: 0.786756453423, SVM: 0.653198653199, KNN: 0.776655443322)\n",
      "                           ('Fare', 'Pclass') -> 0.694725028058 (RF: 0.694725028058, ET: 0.685746352413, SVM: 0.653198653199, KNN: 0.668911335578)\n",
      "                         ('Fare', 'Embarked') -> 0.685746352413 (RF: 0.685746352413, ET: 0.684624017957, SVM: 0.652076318743, KNN: 0.673400673401)\n",
      "                              ('Fare', 'Age') -> 0.673400673401 (RF: 0.652076318743, ET: 0.650953984287, SVM: 0.673400673401, KNN: 0.654320987654)\n",
      "                            ('Sex', 'Pclass') -> 0.776655443322 (RF: 0.776655443322, ET: 0.776655443322, SVM: 0.616161616162, KNN: 0.775533108866)\n",
      "                          ('Sex', 'Embarked') -> 0.786756453423 (RF: 0.786756453423, ET: 0.786756453423, SVM: 0.616161616162, KNN: 0.755331088664)\n",
      "                               ('Sex', 'Age') -> 0.765432098765 (RF: 0.765432098765, ET: 0.76430976431, SVM: 0.632996632997, KNN: 0.744107744108)\n",
      "                       ('Pclass', 'Embarked') -> 0.679012345679 (RF: 0.679012345679, ET: 0.676767676768, SVM: 0.616161616162, KNN: 0.567901234568)\n",
      "                            ('Pclass', 'Age') -> 0.674523007856 (RF: 0.671156004489, ET: 0.674523007856, SVM: 0.632996632997, KNN: 0.659932659933)\n",
      "                          ('Embarked', 'Age') -> 0.62962962963 (RF: 0.589225589226, ET: 0.59595959596, SVM: 0.62962962963, KNN: 0.597081930415)\n",
      "                    ('Fare', 'Sex', 'Pclass') -> 0.791245791246 (RF: 0.784511784512, ET: 0.791245791246, SVM: 0.653198653199, KNN: 0.776655443322)\n",
      "                  ('Fare', 'Sex', 'Embarked') -> 0.783389450056 (RF: 0.776655443322, ET: 0.783389450056, SVM: 0.653198653199, KNN: 0.766554433221)\n",
      "                       ('Fare', 'Sex', 'Age') -> 0.772166105499 (RF: 0.772166105499, ET: 0.765432098765, SVM: 0.673400673401, KNN: 0.694725028058)\n",
      "               ('Fare', 'Pclass', 'Embarked') -> 0.684624017957 (RF: 0.684624017957, ET: 0.680134680135, SVM: 0.65544332211, KNN: 0.667789001122)\n",
      "                    ('Fare', 'Pclass', 'Age') -> 0.675645342312 (RF: 0.671156004489, ET: 0.657687991021, SVM: 0.675645342312, KNN: 0.652076318743)\n",
      "                  ('Fare', 'Embarked', 'Age') -> 0.675645342312 (RF: 0.656565656566, ET: 0.653198653199, SVM: 0.675645342312, KNN: 0.65544332211)\n",
      "                ('Sex', 'Pclass', 'Embarked') -> 0.811447811448 (RF: 0.802469135802, ET: 0.811447811448, SVM: 0.616161616162, KNN: 0.79797979798)\n",
      "                     ('Sex', 'Pclass', 'Age') -> 0.812570145903 (RF: 0.804713804714, ET: 0.812570145903, SVM: 0.634118967452, KNN: 0.766554433221)\n",
      "                   ('Sex', 'Embarked', 'Age') -> 0.754208754209 (RF: 0.754208754209, ET: 0.747474747475, SVM: 0.632996632997, KNN: 0.72278338945)\n",
      "                ('Pclass', 'Embarked', 'Age') -> 0.666666666667 (RF: 0.662177328844, ET: 0.666666666667, SVM: 0.636363636364, KNN: 0.653198653199)\n",
      "        ('Fare', 'Sex', 'Pclass', 'Embarked') -> 0.792368125701 (RF: 0.785634118967, ET: 0.792368125701, SVM: 0.653198653199, KNN: 0.775533108866)\n",
      "             ('Fare', 'Sex', 'Pclass', 'Age') -> 0.806958473625 (RF: 0.806958473625, ET: 0.794612794613, SVM: 0.675645342312, KNN: 0.69696969697)\n",
      "           ('Fare', 'Sex', 'Embarked', 'Age') -> 0.777777777778 (RF: 0.777777777778, ET: 0.76430976431, SVM: 0.674523007856, KNN: 0.702581369248)\n",
      "        ('Fare', 'Pclass', 'Embarked', 'Age') -> 0.674523007856 (RF: 0.668911335578, ET: 0.671156004489, SVM: 0.674523007856, KNN: 0.653198653199)\n",
      "         ('Sex', 'Pclass', 'Embarked', 'Age') -> 0.801346801347 (RF: 0.801346801347, ET: 0.799102132435, SVM: 0.636363636364, KNN: 0.771043771044)\n",
      " ('Fare', 'Sex', 'Pclass', 'Embarked', 'Age') -> 0.803591470258 (RF: 0.803591470258, ET: 0.792368125701, SVM: 0.673400673401, KNN: 0.704826038159)\n"
     ]
    }
   ],
   "source": [
    "def all_combinations(coll):\n",
    "    return reduce(lambda acc, x: acc + list(it.combinations(coll, x)), range(1, len(coll) + 1), [])\n",
    "\n",
    "def right_justify(s):\n",
    "    return \"%45s\" % str(s)\n",
    "\n",
    "train_df = pd.read_csv(\"data/titanic/train.csv\")\n",
    "train_df[\"Sex\"] = train_df[\"Sex\"].apply(lambda sex: 0 if sex == \"male\" else 1)\n",
    "train_df[\"Embarked\"] = train_df[\"Embarked\"].apply(lambda port: 0 if port == \"S\" else 1 if port == \"C\" else 2)\n",
    "\n",
    "meanAge=np.mean(train_df.Age)\n",
    "train_df.Age=train_df.Age.fillna(meanAge)\n",
    "train_df.Cabin = train_df.Cabin.fillna('Unknown')\n",
    "\n",
    "n_samples = len(train_df)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=1, random_state=0)\n",
    "knn = neighbors.KNeighborsClassifier(weights='distance')\n",
    "support_vector_machine = svm.SVC(gamma=0.001)\n",
    "et = ExtraTreesClassifier(n_estimators=100, max_depth=None, min_samples_split=1, random_state=0)\n",
    "\n",
    "all_columns = [\"Fare\", \"Sex\", \"Pclass\", 'Embarked', \"Age\"]\n",
    "\n",
    "\n",
    "for columns in all_combinations(all_columns):\n",
    "    labels = train_df[\"Survived\"].values\n",
    "    features = train_df[list(columns)].values\n",
    "\n",
    "    rf_score = cross_val_score(rf, features, labels, n_jobs=-1).mean()\n",
    "    et_score = cross_val_score(et, features, labels, n_jobs=-1).mean()\n",
    "    svm_score = cross_val_score(support_vector_machine, features, labels, n_jobs=-1).mean()\n",
    "    knn_score = cross_val_score(knn, features, labels, n_jobs=-1).mean()\n",
    "    columns = right_justify(columns)\n",
    "\n",
    "    print(\"{0} -> {5} (RF: {1}, ET: {2}, SVM: {3}, KNN: {4})\".format(columns, rf_score, et_score, svm_score, knn_score, max([rf_score, et_score, svm_score, knn_score])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== survived by class and sex\n",
      "Pclass  Sex     Survived\n",
      "1       female  1           0.968085\n",
      "                0           0.031915\n",
      "        male    0           0.631148\n",
      "                1           0.368852\n",
      "2       female  1           0.921053\n",
      "                0           0.078947\n",
      "        male    0           0.842593\n",
      "                1           0.157407\n",
      "3       female  0           0.500000\n",
      "                1           0.500000\n",
      "        male    0           0.864553\n",
      "                1           0.135447\n",
      "dtype: float64\n",
      "===== train: males\n",
      "              Age        Fare      Pclass       SibSp       Parch\n",
      "count  453.000000  577.000000  577.000000  577.000000  577.000000\n",
      "mean    30.726645   25.523893    2.389948    0.429809    0.235702\n",
      "std     14.678201   43.138263    0.813580    1.061811    0.612294\n",
      "min      0.420000    0.000000    1.000000    0.000000    0.000000\n",
      "25%     21.000000    7.895800    2.000000    0.000000    0.000000\n",
      "50%     29.000000   10.500000    3.000000    0.000000    0.000000\n",
      "75%     39.000000   26.550000    3.000000    0.000000    0.000000\n",
      "max     80.000000  512.329200    3.000000    8.000000    5.000000\n",
      "===== test: males\n",
      "              Age        Fare      Pclass       SibSp       Parch\n",
      "count  205.000000  265.000000  266.000000  266.000000  266.000000\n",
      "mean    30.272732   27.527877    2.334586    0.379699    0.274436\n",
      "std     13.389528   41.079423    0.808497    0.843735    0.883745\n",
      "min      0.330000    0.000000    1.000000    0.000000    0.000000\n",
      "25%     22.000000    7.854200    2.000000    0.000000    0.000000\n",
      "50%     27.000000   13.000000    3.000000    0.000000    0.000000\n",
      "75%     40.000000   26.550000    3.000000    1.000000    0.000000\n",
      "max     67.000000  262.375000    3.000000    8.000000    9.000000\n",
      "===== train: females\n",
      "              Age        Fare      Pclass       SibSp       Parch\n",
      "count  261.000000  314.000000  314.000000  314.000000  314.000000\n",
      "mean    27.915709   44.479818    2.159236    0.694268    0.649682\n",
      "std     14.110146   57.997698    0.857290    1.156520    1.022846\n",
      "min      0.750000    6.750000    1.000000    0.000000    0.000000\n",
      "25%     18.000000   12.071875    1.000000    0.000000    0.000000\n",
      "50%     27.000000   23.000000    2.000000    0.000000    0.000000\n",
      "75%     37.000000   55.000000    3.000000    1.000000    1.000000\n",
      "max     63.000000  512.329200    3.000000    8.000000    6.000000\n",
      "===== test: females\n",
      "              Age        Fare      Pclass       SibSp       Parch\n",
      "count  127.000000  152.000000  152.000000  152.000000  152.000000\n",
      "mean    30.272362   49.747699    2.144737    0.565789    0.598684\n",
      "std     15.428613   73.108716    0.887051    0.974313    1.105434\n",
      "min      0.170000    6.950000    1.000000    0.000000    0.000000\n",
      "25%     20.500000    8.626050    1.000000    0.000000    0.000000\n",
      "50%     27.000000   21.512500    2.000000    0.000000    0.000000\n",
      "75%     38.500000   55.441700    3.000000    1.000000    1.000000\n",
      "max     76.000000  512.329200    3.000000    8.000000    9.000000\n",
      "===== survived by age\n",
      "AgeR      Survived\n",
      "(0, 5]    1           0.704545\n",
      "          0           0.295455\n",
      "(10, 15]  1           0.578947\n",
      "          0           0.421053\n",
      "(15, 20]  0           0.656250\n",
      "          1           0.343750\n",
      "(20, 25]  0           0.655738\n",
      "          1           0.344262\n",
      "(25, 30]  0           0.611111\n",
      "          1           0.388889\n",
      "(30, 40]  0           0.554839\n",
      "          1           0.445161\n",
      "(40, 50]  0           0.616279\n",
      "          1           0.383721\n",
      "(5, 10]   0           0.650000\n",
      "          1           0.350000\n",
      "(50, 60]  0           0.595238\n",
      "          1           0.404762\n",
      "(60, 70]  0           0.764706\n",
      "          1           0.235294\n",
      "(70, 80]  0           0.800000\n",
      "          1           0.200000\n",
      "dtype: float64\n",
      "===== survived by gender and age\n",
      "Sex     AgeR      Survived\n",
      "female  (0, 5]    1           0.761905\n",
      "                  0           0.238095\n",
      "        (10, 15]  1           0.750000\n",
      "                  0           0.250000\n",
      "        (15, 20]  1           0.735294\n",
      "                  0           0.264706\n",
      "        (20, 25]  1           0.755556\n",
      "                  0           0.244444\n",
      "        (25, 30]  1           0.750000\n",
      "                  0           0.250000\n",
      "        (30, 40]  1           0.836364\n",
      "                  0           0.163636\n",
      "        (40, 50]  1           0.677419\n",
      "                  0           0.322581\n",
      "        (5, 10]   0           0.700000\n",
      "                  1           0.300000\n",
      "        (50, 60]  1           0.928571\n",
      "                  0           0.071429\n",
      "        (60, 70]  1           1.000000\n",
      "male    (0, 5]    1           0.652174\n",
      "                  0           0.347826\n",
      "        (10, 15]  0           0.714286\n",
      "                  1           0.285714\n",
      "        (15, 20]  0           0.870968\n",
      "                  1           0.129032\n",
      "        (20, 25]  0           0.896104\n",
      "                  1           0.103896\n",
      "        (25, 30]  0           0.791667\n",
      "                  1           0.208333\n",
      "        (30, 40]  0           0.770000\n",
      "                  1           0.230000\n",
      "        (40, 50]  0           0.781818\n",
      "                  1           0.218182\n",
      "        (5, 10]   0           0.600000\n",
      "                  1           0.400000\n",
      "        (50, 60]  0           0.857143\n",
      "                  1           0.142857\n",
      "        (60, 70]  0           0.928571\n",
      "                  1           0.071429\n",
      "        (70, 80]  0           0.800000\n",
      "                  1           0.200000\n",
      "dtype: float64\n",
      "===== survived by class and age\n",
      "Pclass  AgeR      Survived\n",
      "1       (0, 5]    1           0.666667\n",
      "                  0           0.333333\n",
      "        (10, 15]  1           1.000000\n",
      "        (15, 20]  1           0.800000\n",
      "                  0           0.200000\n",
      "        (20, 25]  1           0.761905\n",
      "                  0           0.238095\n",
      "        (25, 30]  1           0.684211\n",
      "                  0           0.315789\n",
      "        (30, 40]  1           0.755102\n",
      "                  0           0.244898\n",
      "        (40, 50]  1           0.567568\n",
      "                  0           0.432432\n",
      "        (50, 60]  1           0.600000\n",
      "                  0           0.400000\n",
      "        (60, 70]  0           0.818182\n",
      "                  1           0.181818\n",
      "        (70, 80]  0           0.666667\n",
      "                  1           0.333333\n",
      "2       (0, 5]    1           1.000000\n",
      "        (10, 15]  1           1.000000\n",
      "        (15, 20]  0           0.562500\n",
      "                  1           0.437500\n",
      "        (20, 25]  0           0.600000\n",
      "                  1           0.400000\n",
      "        (25, 30]  0           0.580645\n",
      "                  1           0.419355\n",
      "        (30, 40]  0           0.558140\n",
      "                  1           0.441860\n",
      "        (40, 50]  1           0.526316\n",
      "                  0           0.473684\n",
      "        (5, 10]   1           1.000000\n",
      "        (50, 60]  0           0.833333\n",
      "                  1           0.166667\n",
      "        (60, 70]  0           0.666667\n",
      "                  1           0.333333\n",
      "3       (0, 5]    1           0.571429\n",
      "                  0           0.428571\n",
      "        (10, 15]  0           0.571429\n",
      "                  1           0.428571\n",
      "        (15, 20]  0           0.784615\n",
      "                  1           0.215385\n",
      "        (20, 25]  0           0.802817\n",
      "                  1           0.197183\n",
      "        (25, 30]  0           0.724138\n",
      "                  1           0.275862\n",
      "        (30, 40]  0           0.793651\n",
      "                  1           0.206349\n",
      "        (40, 50]  0           0.933333\n",
      "                  1           0.066667\n",
      "        (5, 10]   0           0.812500\n",
      "                  1           0.187500\n",
      "        (50, 60]  0           1.000000\n",
      "        (60, 70]  0           0.666667\n",
      "                  1           0.333333\n",
      "        (70, 80]  0           1.000000\n",
      "dtype: float64\n",
      "Accuracy (k-neighbors): 0.795735129068/0.0111105442611\n",
      "Accuracy (sgd): 0.723905723906/0.0153066012312\n",
      "Accuracy (svm): 0.819304152637/0.0104081015662\n",
      "Accuracy (naive bayes): 0.620650953984/0.163391237085\n",
      "Accuracy (linear regression): 0.824915824916/0.00824744021139\n",
      "Accuracy (logistic regression): 0.81593714927/0.0123965892449\n",
      "Accuracy (random forest): 0.829405162738/0.00419939100648\n",
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   22.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (random forest auto): 0.837261503928 with params {'min_samples_split': 6, 'n_estimators': 400, 'min_samples_leaf': 4}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkoAAAIVCAYAAAAu+9C7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11fea7c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "pd.set_option('display.width', 256)\n",
    "\n",
    "# https://www.dataquest.io/course/kaggle-competitions\n",
    "#\n",
    "# PassengerId -- A numerical id assigned to each passenger.\n",
    "# Survived -- Whether the passenger survived (1), or didn't (0). We'll be making predictions for this column.\n",
    "# Pclass -- The class the passenger was in -- first class (1), second class (2), or third class (3).\n",
    "# Name -- the name of the passenger.\n",
    "# Sex -- The gender of the passenger -- male or female.\n",
    "# Age -- The age of the passenger. Fractional.\n",
    "# SibSp -- The number of siblings and spouses the passenger had on board.\n",
    "# Parch -- The number of parents and children the passenger had on board.\n",
    "# Ticket -- The ticket number of the passenger.\n",
    "# Fare -- How much the passenger paid for the ticker.\n",
    "# Cabin -- Which cabin the passenger was in.\n",
    "# Embarked -- Where the passenger boarded the Titanic.\n",
    "\n",
    "\n",
    "class DataDigest:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.ages = None\n",
    "        self.fares = None\n",
    "        self.titles = None\n",
    "        self.cabins = None\n",
    "        self.families = None\n",
    "        self.tickets = None\n",
    "\n",
    "\n",
    "def get_title(name):\n",
    "    if pd.isnull(name):\n",
    "        return \"Null\"\n",
    "\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1).lower()\n",
    "    else:\n",
    "        return \"None\"\n",
    "\n",
    "\n",
    "def get_family(row):\n",
    "    last_name = row[\"Name\"].split(\",\")[0]\n",
    "    if last_name:\n",
    "        family_size = 1 + row[\"Parch\"] + row[\"SibSp\"]\n",
    "        if family_size > 3:\n",
    "            return \"{0}_{1}\".format(last_name.lower(), family_size)\n",
    "        else:\n",
    "            return \"nofamily\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "def get_index(item, index):\n",
    "    if pd.isnull(item):\n",
    "        return -1\n",
    "\n",
    "    try:\n",
    "        return index.get_loc(item)\n",
    "    except KeyError:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def munge_data(data, digest):\n",
    "    # Age\n",
    "    data[\"AgeF\"] = data.apply(lambda r: digest.ages[r[\"Sex\"]] if pd.isnull(r[\"Age\"]) else r[\"Age\"], axis=1)\n",
    "\n",
    "    # Fare\n",
    "    data[\"FareF\"] = data.apply(lambda r: digest.fares[r[\"Pclass\"]] if pd.isnull(r[\"Fare\"]) else r[\"Fare\"], axis=1)\n",
    "\n",
    "    # Gender\n",
    "    genders = {\"male\": 1, \"female\": 0}\n",
    "    data[\"SexF\"] = data[\"Sex\"].apply(lambda s: genders.get(s))\n",
    "\n",
    "    gender_dummies = pd.get_dummies(data[\"Sex\"], prefix=\"SexD\", dummy_na=False)\n",
    "    data = pd.concat([data, gender_dummies], axis=1)\n",
    "\n",
    "    # Embarkment\n",
    "    embarkments = {\"U\": 0, \"S\": 1, \"C\": 2, \"Q\": 3}\n",
    "    data[\"EmbarkedF\"] = data[\"Embarked\"].fillna(\"U\").apply(lambda e: embarkments.get(e))\n",
    "\n",
    "    embarkment_dummies = pd.get_dummies(data[\"Embarked\"], prefix=\"EmbarkedD\", dummy_na=False)\n",
    "    data = pd.concat([data, embarkment_dummies], axis=1)\n",
    "\n",
    "    # Relatives\n",
    "    data[\"RelativesF\"] = data[\"Parch\"] + data[\"SibSp\"]\n",
    "    data[\"SingleF\"] = data[\"RelativesF\"].apply(lambda r: 1 if r == 0 else 0)\n",
    "\n",
    "    # Deck\n",
    "    decks = {\"U\": 0, \"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"T\": 8}\n",
    "    data[\"DeckF\"] = data[\"Cabin\"].fillna(\"U\").apply(lambda c: decks.get(c[0], -1))\n",
    "\n",
    "    deck_dummies = pd.get_dummies(data[\"Cabin\"].fillna(\"U\").apply(lambda c: c[0]), prefix=\"DeckD\", dummy_na=False)\n",
    "    data = pd.concat([data, deck_dummies], axis=1)\n",
    "\n",
    "    # Titles\n",
    "    title_dummies = pd.get_dummies(data[\"Name\"].apply(lambda n: get_title(n)), prefix=\"TitleD\", dummy_na=False)\n",
    "    data = pd.concat([data, title_dummies], axis=1)\n",
    "\n",
    "    # Lookups\n",
    "    data[\"CabinF\"] = data[\"Cabin\"].fillna(\"unknown\").apply(lambda c: get_index(c, digest.cabins))\n",
    "\n",
    "    data[\"TitleF\"] = data[\"Name\"].apply(lambda n: get_index(get_title(n), digest.titles))\n",
    "\n",
    "    data[\"TicketF\"] = data[\"Ticket\"].apply(lambda t: get_index(t, digest.tickets))\n",
    "\n",
    "    data[\"FamilyF\"] = data.apply(lambda r: get_index(get_family(r), digest.families), axis=1)\n",
    "\n",
    "    # Stat\n",
    "    age_bins = [0, 5, 10, 15, 20, 25, 30, 40, 50, 60, 70, 80, 90]\n",
    "    data[\"AgeR\"] = pd.cut(data[\"Age\"].fillna(-1), bins=age_bins).astype(object)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def linear_scorer(estimator, x, y):\n",
    "    scorer_predictions = estimator.predict(x)\n",
    "\n",
    "    scorer_predictions[scorer_predictions > 0.5] = 1\n",
    "    scorer_predictions[scorer_predictions <= 0.5] = 0\n",
    "\n",
    "    return metrics.accuracy_score(y, scorer_predictions)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# load\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "train_data = pd.read_csv(\"data/titanic/train.csv\")\n",
    "test_data = pd.read_csv(\"data/titanic/test.csv\")\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# stat\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"===== survived by class and sex\")\n",
    "print(train_data.groupby([\"Pclass\", \"Sex\"])[\"Survived\"].value_counts(normalize=True))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# describe\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "describe_fields = [\"Age\", \"Fare\", \"Pclass\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "print(\"===== train: males\")\n",
    "print(train_data[train_data[\"Sex\"] == \"male\"][describe_fields].describe())\n",
    "\n",
    "print(\"===== test: males\")\n",
    "print(test_data[test_data[\"Sex\"] == \"male\"][describe_fields].describe())\n",
    "\n",
    "print(\"===== train: females\")\n",
    "print(train_data[train_data[\"Sex\"] == \"female\"][describe_fields].describe())\n",
    "\n",
    "print(\"===== test: females\")\n",
    "print(test_data[test_data[\"Sex\"] == \"female\"][describe_fields].describe())\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# munge\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "data_digest = DataDigest()\n",
    "\n",
    "data_digest.ages = all_data.groupby(\"Sex\")[\"Age\"].median()\n",
    "data_digest.fares = all_data.groupby(\"Pclass\")[\"Fare\"].median()\n",
    "\n",
    "titles_trn = pd.Index(train_data[\"Name\"].apply(get_title).unique())\n",
    "titles_tst = pd.Index(test_data[\"Name\"].apply(get_title).unique())\n",
    "data_digest.titles = titles_tst\n",
    "\n",
    "families_trn = pd.Index(train_data.apply(get_family, axis=1).unique())\n",
    "families_tst = pd.Index(test_data.apply(get_family, axis=1).unique())\n",
    "data_digest.families = families_tst\n",
    "\n",
    "cabins_trn = pd.Index(train_data[\"Cabin\"].fillna(\"unknown\").unique())\n",
    "cabins_tst = pd.Index(test_data[\"Cabin\"].fillna(\"unknown\").unique())\n",
    "data_digest.cabins = cabins_tst\n",
    "\n",
    "tickets_trn = pd.Index(train_data[\"Ticket\"].fillna(\"unknown\").unique())\n",
    "tickets_tst = pd.Index(test_data[\"Ticket\"].fillna(\"unknown\").unique())\n",
    "data_digest.tickets = tickets_tst\n",
    "\n",
    "train_data_munged = munge_data(train_data, data_digest)\n",
    "test_data_munged = munge_data(test_data, data_digest)\n",
    "all_data_munged = pd.concat([train_data_munged, test_data_munged])\n",
    "\n",
    "predictors = [\"Pclass\",\n",
    "              \"AgeF\",\n",
    "              \"TitleF\",\n",
    "              \"TitleD_mr\", \"TitleD_mrs\", \"TitleD_miss\", \"TitleD_master\", \"TitleD_ms\",\n",
    "              \"TitleD_col\", \"TitleD_rev\", \"TitleD_dr\",\n",
    "              \"CabinF\",\n",
    "              \"DeckF\",\n",
    "              \"DeckD_U\", \"DeckD_A\", \"DeckD_B\", \"DeckD_C\", \"DeckD_D\", \"DeckD_E\", \"DeckD_F\", \"DeckD_G\",\n",
    "              \"FamilyF\",\n",
    "              \"TicketF\",\n",
    "              \"SexF\",\n",
    "              \"SexD_male\", \"SexD_female\",\n",
    "              \"EmbarkedF\",\n",
    "              \"EmbarkedD_S\", \"EmbarkedD_C\", \"EmbarkedD_Q\",\n",
    "              \"FareF\",\n",
    "              \"SibSp\", \"Parch\",\n",
    "              \"RelativesF\",\n",
    "              \"SingleF\"]\n",
    "\n",
    "cv = StratifiedKFold(train_data[\"Survived\"], n_folds=3, shuffle=True, random_state=1)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# stat 2\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "print(\"===== survived by age\")\n",
    "print(train_data_munged.groupby([\"AgeR\"])[\"Survived\"].value_counts(normalize=True))\n",
    "\n",
    "print(\"===== survived by gender and age\")\n",
    "print(train_data_munged.groupby([\"Sex\", \"AgeR\"])[\"Survived\"].value_counts(normalize=True))\n",
    "\n",
    "print(\"===== survived by class and age\")\n",
    "print(train_data_munged.groupby([\"Pclass\", \"AgeR\"])[\"Survived\"].value_counts(normalize=True))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# pairplot graph\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "sns.pairplot(train_data_munged, vars=[\"AgeF\", \"Pclass\", \"SexF\"], hue=\"Survived\", dropna=True)\n",
    "# sns.plt.show()\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# features graph\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(train_data_munged[predictors], train_data_munged[\"Survived\"])\n",
    "\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "# plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# scale\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_data_munged[predictors])\n",
    "\n",
    "# scaled\n",
    "train_data_scaled = scaler.transform(train_data_munged[predictors])\n",
    "test_data_scaled = scaler.transform(test_data_munged[predictors])\n",
    "\n",
    "# non-scaled\n",
    "# train_data_scaled = train_data_munged[predictors]\n",
    "# test_data_scaled = test_data_munged[predictors]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# K-neighbourhood\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "alg_ngbh = KNeighborsClassifier(n_neighbors=3)\n",
    "scores = cross_val_score(alg_ngbh, train_data_scaled, train_data_munged[\"Survived\"], cv=cv, n_jobs=-1)\n",
    "print(\"Accuracy (k-neighbors): {}/{}\".format(scores.mean(), scores.std()))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# sgd\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "alg_sgd = SGDClassifier(random_state=1)\n",
    "scores = cross_val_score(alg_sgd, train_data_scaled, train_data_munged[\"Survived\"], cv=cv, n_jobs=-1)\n",
    "print(\"Accuracy (sgd): {}/{}\".format(scores.mean(), scores.std()))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# svm\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "alg_svm = SVC(C=1.0)\n",
    "scores = cross_val_score(alg_svm, train_data_scaled, train_data_munged[\"Survived\"], cv=cv, n_jobs=-1)\n",
    "print(\"Accuracy (svm): {}/{}\".format(scores.mean(), scores.std()))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# naive bayes\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "alg_nbs = GaussianNB()\n",
    "scores = cross_val_score(alg_nbs, train_data_scaled, train_data_munged[\"Survived\"], cv=cv, n_jobs=-1)\n",
    "print(\"Accuracy (naive bayes): {}/{}\".format(scores.mean(), scores.std()))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# linear regression\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "alg_lnr = LinearRegression()\n",
    "scores = cross_val_score(alg_lnr, train_data_scaled, train_data_munged[\"Survived\"], cv=cv, n_jobs=-1,\n",
    "                         scoring=linear_scorer)\n",
    "print(\"Accuracy (linear regression): {}/{}\".format(scores.mean(), scores.std()))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# logistic regression\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "alg_log = LogisticRegression(random_state=1)\n",
    "scores = cross_val_score(alg_log, train_data_scaled, train_data_munged[\"Survived\"], cv=cv, n_jobs=-1,\n",
    "                         scoring=linear_scorer)\n",
    "print(\"Accuracy (logistic regression): {}/{}\".format(scores.mean(), scores.std()))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# random forest simple\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "alg_frst = RandomForestClassifier(random_state=1, n_estimators=500, min_samples_split=8, min_samples_leaf=2)\n",
    "scores = cross_val_score(alg_frst, train_data_scaled, train_data_munged[\"Survived\"], cv=cv, n_jobs=-1)\n",
    "print(\"Accuracy (random forest): {}/{}\".format(scores.mean(), scores.std()))\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# random forest auto\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "alg_frst_model = RandomForestClassifier(random_state=1)\n",
    "alg_frst_params = [{\n",
    "    \"n_estimators\": [350, 400, 450, 500],\n",
    "    \"min_samples_split\": [6, 8, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}]\n",
    "alg_frst_grid = GridSearchCV(alg_frst_model, alg_frst_params, cv=cv, refit=True, verbose=1, n_jobs=-1)\n",
    "alg_frst_grid.fit(train_data_scaled, train_data_munged[\"Survived\"])\n",
    "alg_frst_best = alg_frst_grid.best_estimator_\n",
    "print(\"Accuracy (random forest auto): {} with params {}\"\n",
    "      .format(alg_frst_grid.best_score_, alg_frst_grid.best_params_))\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# test output\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "alg_test = alg_frst_best\n",
    "\n",
    "alg_test.fit(train_data_scaled, train_data_munged[\"Survived\"])\n",
    "\n",
    "predictions = alg_test.predict(test_data_scaled)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_data[\"PassengerId\"],\n",
    "    \"Survived\": predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(\"titanic-submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong></strong> Represent the following table using \n",
    "a data structure of your choice\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Problem 2</h2><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><p style=\"font-size:120%;\"></strong> Perform Stacking Ensemble analysis on the Boston Housing Data set. You can use Python, Weka, KNIME or other tool to perform Stacking or write your own version in Python code. Include interesting plots and attribute importance analysis to support the choice of the final model configuration chosen. Any combination of any of the Machine learning algorithms we have covered in the class so far or you are already familiar with is acceptable to be used in the Stacking Ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong><p style=\"font-size:120%;\">Question</strong> What problems did you have to deal with when working with these files? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
